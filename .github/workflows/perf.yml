name: Performance

on:
  workflow_call:
    inputs:
      deployment-url:
        description: 'URL to test'
        required: true
        type: string
      runs:
        description: 'Number of Lighthouse runs per page'
        required: false
        default: 1
        type: number
      artifact-name:
        description: 'Name of artifact containing lighthouserc.json'
        required: false
        default: 'hugo-site'
        type: string
  workflow_dispatch:
    inputs:
      deployment-url:
        description: 'URL to test (e.g., https://pikeandwest.com)'
        required: true
        type: string
      runs:
        description: 'Number of Lighthouse runs per page'
        required: false
        default: 3
        type: number

jobs:
  health-check:
    name: Health Check
    runs-on: ubuntu-latest
    timeout-minutes: 2
    steps:
      - name: Wait for deployment
        run: |
          URL="${{ inputs.deployment-url }}"
          echo "Checking $URL..."
          for i in {1..10}; do
            if curl -sf "$URL" > /dev/null; then
              echo "Site is up!"
              exit 0
            fi
            echo "Attempt $i failed, waiting 5s..."
            sleep 5
          done
          echo "Site failed to respond after 10 attempts"
          exit 1

  perf:
    name: ${{ matrix.page.name }}
    needs: health-check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    continue-on-error: true
    permissions:
      contents: read
    strategy:
      fail-fast: false
      matrix:
        page:
          - { name: 'Home', path: '/' }
          - { name: 'About', path: '/about/' }
          - { name: 'Blog', path: '/blog/' }
          - { name: 'Contact', path: '/contact/' }
          - { name: 'Gallery', path: '/gallery-application/' }
    steps:
      - name: Download config
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.artifact-name }}
          path: ./site

      - name: Audit
        id: lighthouse
        uses: treosh/lighthouse-ci-action@v12
        env:
          LHCI_BUILD_CONTEXT__CURRENT_HASH: ${{ github.sha }}
        with:
          urls: ${{ inputs.deployment-url }}${{ matrix.page.path }}
          configPath: ./site/lighthouserc.json
          uploadArtifacts: true
          temporaryPublicStorage: true
          runs: ${{ inputs.runs }}
          artifactName: lhci-${{ matrix.page.name }}

      - name: Save results
        run: |
          mkdir -p results
          echo '${{ steps.lighthouse.outputs.manifest }}' > results/${{ matrix.page.name }}.json
          echo '${{ steps.lighthouse.outputs.links }}' > results/${{ matrix.page.name }}-links.json

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: perf-${{ matrix.page.name }}
          path: results/
          retention-days: 30

    outputs:
      manifest: ${{ steps.lighthouse.outputs.manifest }}

  summary:
    name: Summary
    needs: perf
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 2
    permissions:
      contents: write
      pull-requests: write
    outputs:
      avg-performance: ${{ steps.analyze.outputs.avg-performance }}
      has-regression: ${{ steps.analyze.outputs.has-regression }}
    steps:
      - name: Download results
        uses: actions/download-artifact@v4
        with:
          pattern: perf-*
          path: results/
          merge-multiple: true

      - name: Analyze and generate summary
        id: analyze
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            const resultsDir = 'results';
            const files = fs.readdirSync(resultsDir).filter(f => f.endsWith('.json') && !f.includes('-links'));

            let rows = [];
            let allPassed = true;
            let totalPerf = 0;
            let pageCount = 0;

            const scores = {};

            for (const file of files) {
              const pageName = file.replace('.json', '');
              const content = fs.readFileSync(path.join(resultsDir, file), 'utf8');

              // Handle empty or invalid JSON
              if (!content || content.trim() === '' || content.trim() === 'undefined') {
                rows.push(`| ${pageName} | âš ï¸ N/A | âš ï¸ N/A | âš ï¸ N/A | âš ï¸ N/A |`);
                continue;
              }

              let manifest;
              try {
                manifest = JSON.parse(content);
              } catch (e) {
                rows.push(`| ${pageName} | âš ï¸ Error | âš ï¸ Error | âš ï¸ Error | âš ï¸ Error |`);
                continue;
              }

              const linksFile = path.join(resultsDir, `${pageName}-links.json`);
              let reportLink = '';

              if (fs.existsSync(linksFile)) {
                try {
                  const linksContent = fs.readFileSync(linksFile, 'utf8');
                  if (linksContent && linksContent.trim() !== '' && linksContent.trim() !== 'undefined') {
                    const links = JSON.parse(linksContent);
                    reportLink = Object.values(links)[0] || '';
                  }
                } catch (e) {
                  console.log('Could not parse links file:', e);
                }
              }

              if (manifest && manifest.length > 0) {
                const result = manifest[0];
                const summary = result.summary || {};

                scores[pageName] = summary;

                const getScore = (key) => {
                  const score = summary[key];
                  if (score === undefined || score === null) return { display: 'N/A', value: null };
                  const pct = Math.round(score * 100);
                  const emoji = pct >= 90 ? 'ğŸŸ¢' : pct >= 50 ? 'ğŸŸ ' : 'ğŸ”´';
                  if (pct < 90) allPassed = false;
                  return { display: `${emoji} ${pct}`, value: pct };
                };

                const perf = getScore('performance');
                if (perf.value !== null) {
                  totalPerf += perf.value;
                  pageCount++;
                }

                const pageLink = reportLink ? `[${pageName}](${reportLink})` : pageName;
                rows.push(`| ${pageLink} | ${perf.display} | ${getScore('accessibility').display} | ${getScore('best-practices').display} | ${getScore('seo').display} |`);
              }
            }

            const avgPerf = pageCount > 0 ? Math.round(totalPerf / pageCount) : 0;
            const statusEmoji = allPassed ? 'âœ…' : 'âš ï¸';
            const statusText = allPassed ? 'All checks passed!' : 'Some scores below 90';

            // Generate markdown summary
            const summary = `## ${statusEmoji} Lighthouse Report

            ${statusText} | Average Performance: **${avgPerf}**

            | Page | Perf | A11y | Best Practices | SEO |
            |------|------|------|----------------|-----|
            ${rows.join('\n')}

            <details>
            <summary>Score Legend</summary>

            - ğŸŸ¢ 90-100: Good
            - ğŸŸ  50-89: Needs Improvement
            - ğŸ”´ 0-49: Poor

            </details>

            > Median of ${{ inputs.runs }} run(s). Click page names for full reports.
            `;

            // Write to job summary
            await core.summary.addRaw(summary).write();

            // Set outputs
            core.setOutput('avg-performance', avgPerf);
            core.setOutput('has-regression', avgPerf < 80 ? 'true' : 'false');

            // Save scores for badge/history
            fs.writeFileSync('scores.json', JSON.stringify({
              timestamp: new Date().toISOString(),
              url: '${{ inputs.deployment-url }}',
              avgPerformance: avgPerf,
              allPassed: allPassed,
              pages: scores
            }, null, 2));

            return summary;

      - name: Upload scores
        uses: actions/upload-artifact@v4
        with:
          name: perf-scores
          path: scores.json
          retention-days: 90

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync(process.env.GITHUB_STEP_SUMMARY, 'utf8');

            const { data: comments } = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' && comment.body.includes('Lighthouse Report')
            );

            const body = summary;

            if (botComment) {
              await github.rest.issues.updateComment({
                comment_id: botComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }

  label:
    name: Label PR
    needs: summary
    if: github.event_name == 'pull_request' && needs.summary.outputs.has-regression == 'true'
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
    steps:
      - name: Add regression label
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.addLabels({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: ['perf-regression']
            });

  badge:
    name: Update Badge
    needs: summary
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Download scores
        uses: actions/download-artifact@v4
        with:
          name: perf-scores
          path: ./

      - name: Update badge and history
        run: |
          # Read scores
          SCORE=$(jq -r '.avgPerformance' scores.json)
          TIMESTAMP=$(jq -r '.timestamp' scores.json)

          # Determine badge color
          if [ "$SCORE" -ge 90 ]; then
            COLOR="brightgreen"
          elif [ "$SCORE" -ge 50 ]; then
            COLOR="yellow"
          else
            COLOR="red"
          fi

          # Create badge JSON for shields.io endpoint
          mkdir -p .github/badges
          echo "{\"schemaVersion\":1,\"label\":\"lighthouse\",\"message\":\"${SCORE}\",\"color\":\"${COLOR}\"}" > .github/badges/lighthouse.json

          # Append to history (keep last 100 entries)
          HISTORY_FILE=".github/perf-history.json"
          if [ -f "$HISTORY_FILE" ]; then
            jq --argjson new "$(cat scores.json)" '.entries += [$new] | .entries = .entries[-100:]' "$HISTORY_FILE" > tmp.json && mv tmp.json "$HISTORY_FILE"
          else
            echo "{\"entries\": [$(cat scores.json)]}" > "$HISTORY_FILE"
          fi

      - name: Commit badge
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add .github/badges/ .github/perf-history.json
          git diff --staged --quiet || git commit -m "chore: update lighthouse badge [skip ci]"
          git push || echo "Nothing to push"
